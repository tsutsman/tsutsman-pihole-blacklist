# Project roadmap

## 0. Planning principles
- **Release cadence:** two-week sprints with retrospectives and checkpoints.
- **Definition of done:** successful `pre-commit`, `pytest`, list generation,
  refreshed metadata, changelog, and release notes.
- **Control metrics:** false-positive rate, incident response time, test
  coverage, source refresh frequency, and release SLA.

## 1. Step 1. Stabilise the foundations
### 1.1. Data quality
- Perform a full audit of `domains.txt` and `regex.list` focusing on duplicates,
  stale entries, and divergences from `data/catalog.json`.
- Standardise metadata: enforce `category`, `regions`, `sources`, and `status`
  for all active entries.
- Expand `data/false_positives.json` using user feedback and establish a rapid
  rollback procedure.

### 1.2. Verification automation
- Add coverage reporting (`coverage.py`) to `pytest` and make the 85% threshold
  mandatory in CI.
- Extend GitHub Actions with static checks: `pip-audit` for dependencies and
  `bandit` for script security.
- Store generated list artifacts in GitHub Actions and verify hashes.

### 1.3. Documentation and process
- Update `README.md` with the inclusion policy and metadata requirements.
- Create issue/PR templates that capture data sources and risk assessments.
- Maintain a journaled `CHANGELOG.md` with release descriptions generated by a
  helper script.

## 2. Step 2. Expand capabilities
### 2.1. Analytics and monitoring
- Build dashboards (Grafana/Metabase) using `reports/` data to track trends,
  metadata coverage, and refresh cadence.
- Introduce a false-positive reporting pipeline via webhook or form that feeds
  directly into the review backlog.
- Add historical change logs in `reports/` with release comparisons (diff
  reports).

### 2.2. Source expansion and trust scoring
- Review `data/sources.json`, assign reliability weights, and disable low-SLA
  feeds automatically.
- Integrate at least two threat-intelligence APIs (VirusTotal, AbuseIPDB) with
  caching.
- Implement weighted prioritisation for new domains based on risk and source
  reliability.

### 2.3. CI/CD and releases
- Automate GitHub releases from tags and attach generated list bundles.
- Provision a Pi-hole container for pre-release end-to-end validation (smoke
  tests on core segments).
- Set an SLA: ≤48 hours between discovering a critical threat and releasing an
  updated list.

## 3. Step 3. Sustainable growth
### 3.1. Intelligent methods
- Explore ML/heuristic approaches to detect malicious domains using behavioural
  signals.
- Build a scoring prototype and feed its suggestions into `update_domains.py`.
- Add manual approval workflows with detailed decision logging.

### 3.2. Scalability and resilience
- Enable backups for metadata and lists (S3/Backblaze) with at least six months
  of retention.
- Prepare a resilience plan (artifact replication, fallback CDN for list
  distribution).
- Optimise the `reports/` structure and distributions for large data volumes
  (incremental updates, differential lists).

### 3.3. Community and partnerships
- Launch a volunteer/partner validation program: early access to releases in
  exchange for feedback.
- Partner with cybersecurity organisations to exchange indicators of compromise.
- Expose an API for segmented lists with access control and rate limiting.

## 4. Success metrics
- **False positives:** <1% removal requests within 30 days after a release.
- **Test coverage:** ≥85% overall, ≥90% for critical modules
  (`scripts/check_lists.py`, `scripts/update_domains.py`).
- **Response speed:** critical updates ≤24 hours, routine updates ≤7 days.
- **Transparency:** every release ships with a changelog, diff report, and
  refreshed dashboard metrics.

## 5. Governance and reviews
- Review the roadmap and metrics monthly and update the backlog.
- Hold quarterly strategy sessions to reprioritise long-term initiatives.
- Document owners for each stream and rotate responsibilities to avoid
  bottlenecks.
